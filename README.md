# Mistral-Finetunnig-LTSM
Fine-tuning Mistral-7B using LoRA and 4-bit quantization for efficient keyword generation. Trained on custom prompt-output JSONL data. Supports re-finetuning, runs on Colab with A100/L4 GPU, and saves models to Google Drive. Ideal for SEO keyword and content tag generation.
